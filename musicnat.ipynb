{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "from the code folder, run the following command:\n",
    "```\n",
    "conda env update --file environment.yml\n",
    "```\n",
    "And then activate the new environment:\n",
    "```\n",
    "conda activate musicnat\n",
    "```\n",
    "The full code can be found here:\n",
    "https://github.com/pelednoam/musicnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing the audio files\n",
    "\n",
    "### Converting mid to wav \n",
    "After trying without success to parse the mid files using many different python packages, on different operating systems, I decided I will first convert all of them to wav\n",
    "\n",
    "### Reading the wav files\n",
    "This code  iterates on the files, both for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import glob\n",
    "\n",
    "TRAINING_FOL = 'training-folder-with-audio-files'\n",
    "TESTING_FOL = 'testing-folder-with-flat-audio-files'\n",
    "\n",
    "def songs_iterator(songs_fol, songs_type='wav'):\n",
    "    if songs_fol == TRAINING_FOL:\n",
    "        composers = [op.basename(d) for d in glob.glob(op.join(songs_fol, '*')) if op.isdir(d)]\n",
    "        for composer in composers:\n",
    "            for song_fname in glob.glob(op.join(songs_fol, composer, '*.{}'.format(songs_type))):\n",
    "                yield song_fname, composer\n",
    "    elif songs_fol == TESTING_FOL:\n",
    "        for song_fname in glob.glob(op.join(songs_fol, '*.{}'.format(songs_type))):\n",
    "            yield song_fname, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features extraction\n",
    "\n",
    "The next step is the extract the features from the audio files. The function get 5 parameters:\n",
    "* songs_fol: The root directory of the songs\n",
    "* buffer_len: The songs are read using sliding window to emulate reading from buffers of buffer_len seconds\n",
    "* buffer_shift: The shift (in seconds) of the window\n",
    "* songs_type: What songs type to look for (wav/mp3...)\n",
    "* n_jobs: The analysis can be paralleled using n_jobs jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import songs_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_audio_files(songs_fol, buffer_len=30, buffer_shift=10, songs_type='wav', n_jobs=4):\n",
    "    is_training = songs_fol == TRAINING_FOL\n",
    "    songs_composers_fname = op.join(PROJECT_FOL, 'songs_composers.pkl')\n",
    "    songs_features_fname = op.join(PROJECT_FOL, 'songs_features_{}.csv'.format(\n",
    "        'training' if is_training else 'testing'))\n",
    "    songs_fnames = []\n",
    "    songs_composers = {}\n",
    "    all_features = pd.DataFrame(columns=songs_utils.columns(), dtype=np.float32)\n",
    "    for song_fname, composer in songs_iterator(songs_fol, songs_type):\n",
    "        file_name = op.basename(song_fname)\n",
    "        songs_fnames.append(song_fname)\n",
    "        if is_training:\n",
    "            songs_composers[file_name] = composer\n",
    "    # Separate the data into n_jobs chunks\n",
    "    indices = np.array_split(np.arange(len(songs_fnames)), n_jobs)\n",
    "    chunks = [([songs_fnames[info_ind] for info_ind in indices_chunk], buffer_len, buffer_shift)\n",
    "              for indices_chunk in indices]\n",
    "    results = utils.run_parallel(calc_songs_features, chunks, n_jobs)\n",
    "    # Go over the results from the different chunks and concatenate them\n",
    "    for chunk_features in results:\n",
    "        all_features = pd.concat([all_features, chunk_features])\n",
    "    print('Writing songs in {}'.format(songs_features_fname))\n",
    "    all_features.to_csv(songs_features_fname)\n",
    "    if is_training:\n",
    "        utils.save(songs_composers, songs_composers_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be run the following function in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def calc_songs_features(params):\n",
    "    songs_fnames, buffer_len, buffer_shift = params\n",
    "    chunk_features = pd.DataFrame(columns=songs_utils.columns(), dtype=np.float32)\n",
    "    for song_fname in tqdm(songs_fnames):\n",
    "        all_features = songs_utils.compute_features(song_fname, buffer_len, buffer_shift)\n",
    "        # Go over the features from the different buffers (windows) and add them to the DataFrame\n",
    "        for buffer_ind, features in enumerate(all_features):\n",
    "            key = '{}_{}'.format(op.basename(song_fname), buffer_ind)\n",
    "            if features is not None:\n",
    "                chunk_features.loc[key] = features\n",
    "    return chunk_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will run the actual function that computes the features, songs_utils.compute_features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns():\n",
    "    feature_sizes = dict(chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
    "                         tonnetz=6, mfcc=20, rmse=1, zcr=1,\n",
    "                         spectral_centroid=1, spectral_bandwidth=1,\n",
    "                         spectral_contrast=7, spectral_rolloff=1)\n",
    "    moments = ('mean', 'std', 'skew', 'kurtosis', 'median', 'min', 'max')\n",
    "\n",
    "    columns = []\n",
    "    for name, size in feature_sizes.items():\n",
    "        for moment in moments:\n",
    "            it = ((name, moment, '{:02d}'.format(i+1)) for i in range(size))\n",
    "            columns.extend(it)\n",
    "\n",
    "    names = ('feature', 'statistics', 'number')\n",
    "    columns = pd.MultiIndex.from_tuples(columns, names=names)\n",
    "\n",
    "    # More efficient to slice if indexes are sorted.\n",
    "    return columns.sort_values()\n",
    "\n",
    "\n",
    "def compute_features(song_fname, buffer_len=30, buffer_shift=10):\n",
    "    from scipy import stats\n",
    "    import librosa\n",
    "\n",
    "    def feature_stats(name, values):\n",
    "        features[name, 'mean'] = np.mean(values, axis=1)\n",
    "        features[name, 'std'] = np.std(values, axis=1)\n",
    "        features[name, 'skew'] = stats.skew(values, axis=1)\n",
    "        features[name, 'kurtosis'] = stats.kurtosis(values, axis=1)\n",
    "        features[name, 'median'] = np.median(values, axis=1)\n",
    "        features[name, 'min'] = np.min(values, axis=1)\n",
    "        features[name, 'max'] = np.max(values, axis=1)\n",
    "\n",
    "    all_x, sr = librosa.load(song_fname, sr=None, mono=True)  # kaiser_fast\n",
    "    # Calculate the sliding windows\n",
    "    windows = utils.calc_windows(len(all_x), buffer_len * sr, buffer_shift * sr)\n",
    "    all_features = []\n",
    "    for window in windows:\n",
    "        features = pd.Series(index=columns(), dtype=np.float32, name=song_fname)\n",
    "\n",
    "        # Creating a buffer of buffer_len seconds\n",
    "        x = all_x[window[0]: window[1]]\n",
    "\n",
    "        try:\n",
    "            f = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
    "            feature_stats('zcr', f)\n",
    "\n",
    "            cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12,\n",
    "                                     n_bins=7*12, tuning=None))\n",
    "            assert cqt.shape[0] == 7 * 12\n",
    "            assert np.ceil(len(x)/512) <= cqt.shape[1] <= np.ceil(len(x)/512)+1\n",
    "\n",
    "            f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "            feature_stats('chroma_cqt', f)\n",
    "            f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "            feature_stats('chroma_cens', f)\n",
    "            f = librosa.feature.tonnetz(chroma=f)\n",
    "            feature_stats('tonnetz', f)\n",
    "\n",
    "            stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "            f = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
    "            feature_stats('chroma_stft', f)\n",
    "\n",
    "            f = librosa.feature.spectral_centroid(S=stft)\n",
    "            feature_stats('spectral_centroid', f)\n",
    "            f = librosa.feature.spectral_bandwidth(S=stft)\n",
    "            feature_stats('spectral_bandwidth', f)\n",
    "            f = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
    "            feature_stats('spectral_contrast', f)\n",
    "            f = librosa.feature.spectral_rolloff(S=stft)\n",
    "            feature_stats('spectral_rolloff', f)\n",
    "\n",
    "            mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "            del stft\n",
    "            f = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "            feature_stats('mfcc', f)\n",
    "\n",
    "            all_features.append(features)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('{}: {}'.format(song_fname, repr(e)))\n",
    "            features = None\n",
    "\n",
    "    return all_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is based on the following paper: </br>\n",
    "https://arxiv.org/abs/1612.01840 </br>\n",
    "The paper describes a free audio dataset (FMA), and discusses how to evaluate some baselines for genre recognition.\n",
    "In their code, they used the library librosa to calculate features from audio files.\n",
    "I used their code here, with small variations, to calculate the same list of features as in their paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We will read the features from the csv file, and prepare the data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(songs_train_features_fname, index_col=0, header=[0, 1, 2])\n",
    "songs_names = get_songs_names(train_features)\n",
    "songs_composers = utils.load(songs_composers_fname)\n",
    "labels = [songs_composers[get_song_name(buffer_name, True)] for buffer_name in train_features.index]\n",
    "\n",
    "X = standardize_features(train_features)\n",
    "y = encode_labels(labels)\n",
    "\n",
    "\n",
    "def standardize_features(features):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    X = features.values\n",
    "    # Remove nans\n",
    "    X[np.where(np.isnan(X))] = 0\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def encode_labels(labels):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # Encode the labels\n",
    "    enc = LabelEncoder()\n",
    "    y = enc.fit_transform(labels)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection\n",
    "Next, we will do dimensionality reduction. The number of features (518) is too high, compared to the number of examples in the dataset. This can cause overfitting of the model.\n",
    "To solve this issue, we will use features selection using SelectKBest and mutual information statistics to score the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "features_selection_model = SelectKBest(mutual_info_classif, k=features_selection_num).fit(X, y)\n",
    "utils.save(features_selection_model, op.join(PROJECT_FOL, 'features_selection_model.pkl'))\n",
    "X = features_selection_model.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where here I set features_selection_num=50. This number should be tuned in the future. The features_selection_model is saved to be used on the testing dataset.\n",
    "\n",
    "Next, we will identify and compare a list of classifiers to use on the data. We will only use classifiers that can calculate the labels' probabilities and not only predict the labels. We will later use these probabilities to find outliers.\n",
    "\n",
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifiers():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.experimental import enable_halving_search_cv\n",
    "    from sklearn.model_selection import HalvingGridSearchCV\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "    # Identify the possible hyper params for rbf SVC\n",
    "    gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    Cs = [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "    svc_rbf_params_grid = {\"gamma\": gammas, \"C\": Cs}\n",
    "    scv_rbf_clf = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "    # Identify the possible hyper params for poly SVC\n",
    "    poly_degrees = np.arange(1, 11)\n",
    "    svc_poly_params_grid = {\"degree\": poly_degrees}\n",
    "    scv_poly_clf = SVC(kernel='poly', probability=True)\n",
    "\n",
    "    classifiers = {\n",
    "        'LR1': LogisticRegression(penalty='l1', max_iter=2000, solver='liblinear'),\n",
    "        'LR2': LogisticRegression(penalty='l2', max_iter=2000),\n",
    "        'kNN': KNeighborsClassifier(),\n",
    "        'SCVrbf': HalvingGridSearchCV(\n",
    "            estimator=scv_rbf_clf, param_grid=svc_rbf_params_grid, factor=3),\n",
    "        'SVCpoly': HalvingGridSearchCV(\n",
    "            estimator=scv_poly_clf, param_grid=svc_poly_params_grid, factor=3), \n",
    "        'linSVC': SVC(kernel='linear', probability=True),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'ExtraTrees': ExtraTreesClassifier(n_estimators=100),\n",
    "        'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "        'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    }\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tuning the hyperparams, we are using here HalvingGridSearchCV, which is faster than the GridSearchCV.\n",
    "\n",
    "## train test split\n",
    "Our data is highly imbalanced. To avoid bias toward one of the labels, we will calculate which label with the smallest number of items, and pick the same number of items from each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_equally(y, n_split=10, test_size=0.1):\n",
    "    from collections import Counter\n",
    "    from operator import itemgetter\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    y_count = Counter(y)\n",
    "    # Find the lowest number of items\n",
    "    n_per_class = min(y_count.items(), key=itemgetter(1))[1]\n",
    "    inds_all = []\n",
    "    for _ in range(n_split):\n",
    "        inds_train, inds_test = np.array([], dtype=np.int64), np.array([], dtype=np.int64)\n",
    "        for label in set(y):\n",
    "            select_inds = np.random.choice(np.where(y == label)[0], n_per_class, replace=False)\n",
    "            if test_size > 0:\n",
    "                label_inds_train, label_inds_test = train_test_split(select_inds, test_size=test_size)\n",
    "            else:\n",
    "                # No test, only train\n",
    "                label_inds_train, label_inds_test = select_inds, []\n",
    "            inds_train = np.concatenate((inds_train, label_inds_train))\n",
    "            inds_test = np.concatenate((inds_test, label_inds_test))\n",
    "        inds_all.append((inds_train, inds_test))\n",
    "    return inds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where n_split is the number of splits, and test_size is the test size (0-1). This function randomly chooses n_per_class items from each class, and divides them into train and test indices using  sklearn.model_selection.train_test_split.\n",
    "\n",
    "## Fit, predict, and calculate the scores for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_training_scores(X, y, classifiers, figures_fol, songs_names, overwrite=False):\n",
    "    from collections import defaultdict\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    scores_fname = op.join(PROJECT_FOL, 'all_train_scores.pkl')\n",
    "    # If we've already ran this function, and don't want to overwrite, we can just load the scores\n",
    "    if op.isfile(scores_fname) and not overwrite:\n",
    "        all_scores, conf_mats = utils.load(scores_fname)\n",
    "        return all_scores, conf_mats\n",
    "\n",
    "    all_scores, all_probs_scores, conf_mats = defaultdict(list), defaultdict(list), {}\n",
    "    labels_num = len(set(y))\n",
    "    # Split equally (same number of items per label) using 10 splits and 10% for testing \n",
    "    data_split = split_equally(y, n_split=10, test_size=0.1)\n",
    "    for clf_name, clf in tqdm(classifiers.items()):\n",
    "        conf_mat = np.zeros((labels_num, labels_num))\n",
    "        for split_ind, (train, test) in enumerate(data_split):\n",
    "            clf.fit(X[train], y[train])\n",
    "            pred_model = clf.predict(X[test])\n",
    "            probs = clf.predict_proba(X[test])\n",
    "            # Calculate the different scores\n",
    "            conf_mat += confusion_matrix(pred_model, y[test])\n",
    "            score = clf.score(X[test], y[test])\n",
    "            # Calc how much the classifer is \"sure\" about the decision \n",
    "            max_prob_score = np.mean(np.max(probs, axis=1))\n",
    "            # Calc how much the classifer is \"uncertain\" about the decision\n",
    "            var_prob_score = np.mean(np.var(probs, axis=1))\n",
    "            roc_auc_ovo, roc_auc_ovr = calc_auc(y[test], probs)\n",
    "            all_scores[clf_name].append((score, max_prob_score,  var_prob_score, roc_auc_ovo, roc_auc_ovr))\n",
    "        conf_mats[clf_name] = conf_mat\n",
    "    utils.save((all_scores, conf_mats), scores_fname)\n",
    "    return all_scores, conf_mats\n",
    "\n",
    "\n",
    "def calc_auc(y_test, y_prob):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class=\"ovo\", average=\"macro\") # One-vs-one\n",
    "    roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\") # One-vs-rest\n",
    "    return roc_auc_ovo, roc_auc_ovr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit, predict, and calculate the scores for each label\n",
    "This step is similar to the previous one, only here we aren't splitting the data into train and test, but using all the records for train, to be used on the songs that aren't labeled. We will use the same split_equally, to randomly choose many times n_per_class items from each class, to have different versions from each classifier. For that, we will call split_equally again, this time with test_size=0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_save_classifiers(classifiers, X, y, all_scores, conf_mats, models_fol):\n",
    "    for clf_name, clf in tqdm(classifiers.items()):\n",
    "        # Calculate the mean (over the splits) for the classifier's scores\n",
    "        score, max_probs_score, var_prob_score, roc_auc_ovo, roc_auc_ovr = calc_mean_scores(all_scores, clf_name)\n",
    "        # Create 10 random equally selected train sets and save the classifiers\n",
    "        all_data_split = split_equally(y, n_split=10, test_size=0)\n",
    "        for split_ind, (train, _) in enumerate(all_data_split):\n",
    "            clf.fit(X[train], y[train])\n",
    "            utils.save(clf, op.join(models_fol, '{}_{}.pkl'.format(clf_name, split_ind)))\n",
    "\n",
    "\n",
    "def calc_mean_scores(all_scores, clf_name):\n",
    "    score = np.mean([scores[0] for scores in all_scores[clf_name]])\n",
    "    max_probs_score = np.mean([scores[1] for scores in all_scores[clf_name]])\n",
    "    var_prob_score = np.mean([scores[2] for scores in all_scores[clf_name]])\n",
    "    roc_auc_ovo = np.mean([scores[3] for scores in all_scores[clf_name]])\n",
    "    roc_auc_ovr = np.mean([scores[4] for scores in all_scores[clf_name]])\n",
    "    return score, max_probs_score, var_prob_score, roc_auc_ovo, roc_auc_ovr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to save all the classifiers, or to use the scores to save only the good ones. I decided to save all of them, and used the scores where we predict the test labels.\n",
    "Overall, the training function looks like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(overwrite=False):\n",
    "    songs_composers_fname = op.join(PROJECT_FOL, 'songs_composers.pkl')\n",
    "    songs_features_fname = op.join(PROJECT_FOL, 'songs_features.csv')\n",
    "    figures_fol = utils.make_dir(op.join(PROJECT_FOL, 'figures_train'))\n",
    "    models_fol = utils.make_dir(op.join(PROJECT_FOL, 'models'))\n",
    "\n",
    "    features = pd.read_csv(songs_features_fname, index_col=0, header=[0, 1, 2])\n",
    "    songs_names = get_songs_names(features)\n",
    "    songs_composers = utils.load(songs_composers_fname)\n",
    "    # Find all the labels from thte buffer names\n",
    "    labels = [songs_composers[get_song_name(buffer_name, True)] for buffer_name in features.index]\n",
    "\n",
    "    X = standardize_features(train_features)\n",
    "    y = encode_labels(labels)\n",
    "\n",
    "    # Features selection\n",
    "    features_selection_model = SelectKBest(mutual_info_classif, k=features_selection_num).fit(X, y)\n",
    "    utils.save(features_selection_model, op.join(PROJECT_FOL, 'features_selection_model.pkl'))\n",
    "    X = features_selection_model.transform(X)\n",
    "\n",
    "    classifiers = get_classifiers()\n",
    "    all_scores, conf_mats = calc_training_scores(X, y, classifiers, figures_fol, songs_names, overwrite)\n",
    "    fit_and_save_classifiers(classifiers, X, y, all_scores, conf_mats, models_fol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Here are the results of the best classifiers - high score, high certainty (max_probs) and high AUC:\n",
    "\n",
    "Classifier: MLP2 <br/>\n",
    "score: 0.861, max_probs: 0.938, var_probs: 0.165, roc_auc: 0.967 <br/>\n",
    "Confusion matrix: <br/>\n",
    "88, 1, 1, 1 <br/>\n",
    "1, 73, 6, 8 <br/>\n",
    "0, 6, 75, 7 <br/>\n",
    "1, 10, 8, 74 <br/>\n",
    "\n",
    "Classifier: MLP1 <br/>\n",
    "score: 0.856, max_probs: 0.914, var_probs: 0.157, roc_auc: 0.968 <br/>\n",
    "Confusion matrix: <br/>\n",
    "88, 3, 1, 2 <br/>\n",
    "1, 72, 8, 9 <br/>\n",
    "0, 6, 75, 6 <br/>\n",
    "1, 9, 6, 73 <br/>\n",
    "\n",
    "Classifier: SCVrbf <br/>\n",
    "score: 0.861, max_probs: 0.804, var_probs: 0.115, roc_auc: 0.970 <br/>\n",
    "Confusion matrix: <br/>\n",
    "89, 1, 2, 2 <br/>\n",
    "0, 72, 6, 8 <br/>\n",
    "0, 7, 77, 8 <br/>\n",
    "1, 10, 5, 72 <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the rest of the classifiers:\n",
    "\n",
    "Classifier: ExtraTrees <br/>\n",
    "score: 0.828, max_probs: 0.703, var_probs: 0.085, roc_auc: 0.961 <br/>\n",
    "Confusion matrix: <br/>\n",
    "89, 2, 1, 2 <br/>\n",
    "0, 60, 5, 7 <br/>\n",
    "0, 17, 81, 13 <br/>\n",
    "1, 11, 3, 68 <br/>\n",
    "\n",
    "Classifier: RandomForest <br/>\n",
    "score: 0.806, max_probs: 0.680, var_probs: 0.078, roc_auc: 0.946 <br/>\n",
    "Confusion matrix: <br/>\n",
    "89, 2, 3, 4 <br/>\n",
    "0, 63, 9, 9 <br/>\n",
    "0, 16, 74, 13 <br/>\n",
    "1, 9, 4, 64 <br/>\n",
    "\n",
    "Classifier: kNN <br/>\n",
    "score: 0.806, max_probs: 0.824, var_probs: 0.130, roc_auc: 0.947 <br/>\n",
    "Confusion matrix: <br/>\n",
    "89, 1, 2, 5 <br/>\n",
    "0, 60, 5, 9 <br/>\n",
    "0, 14, 76, 11 <br/>\n",
    "1, 15, 7, 65 <br/>\n",
    "\n",
    "Classifier: LR1 <br/>\n",
    "score: 0.744, max_probs: 0.703, var_probs: 0.084, roc_auc: 0.913 <br/>\n",
    "Confusion matrix: <br/>\n",
    "86, 3, 4, 4 <br/>\n",
    "3, 61, 11, 14 <br/>\n",
    "0, 12, 64, 15 <br/>\n",
    "1, 14, 11, 57 <br/>\n",
    "\n",
    "Classifier: LR2 <br/>\n",
    "score: 0.758, max_probs: 0.787, var_probs: 0.113, roc_auc: 0.918 <br/>\n",
    "Confusion matrix: <br/>\n",
    "86, 2, 4, 2 <br/>\n",
    "3, 63, 12, 16 <br/>\n",
    "0, 9, 63, 11 <br/>\n",
    "1, 16, 11, 61 <br/>\n",
    "\n",
    "Classifier: SVCpoly <br/>\n",
    "score: 0.750, max_probs: 0.681, var_probs: 0.080, roc_auc: 0.923 <br/>\n",
    "Confusion matrix: <br/>\n",
    "89, 4, 4, 7 <br/>\n",
    "1, 51, 7, 10 <br/>\n",
    "0, 17, 70, 13 <br/>\n",
    "0, 18, 9, 60 <br/>\n",
    "\n",
    "Classifier: linSVC <br/>\n",
    "score: 0.744, max_probs: 0.650, var_probs: 0.072, roc_auc: 0.923 <br/>\n",
    "Confusion matrix: <br/>\n",
    "86, 3, 4, 3 <br/>\n",
    "1, 65, 16, 21 <br/>\n",
    "0, 7, 62, 11 <br/>\n",
    "3, 15, 8, 55 <br/>\n",
    "\n",
    "Classifier: DecisionTree <br/>\n",
    "score: 0.653, max_probs: 1.000, var_probs: 0.188, roc_auc: 0.769 <br/>\n",
    "Confusion matrix: <br/>\n",
    "73, 11, 6, 12 <br/>\n",
    "6, 53, 13, 21 <br/>\n",
    "3, 11, 64, 12 <br/>\n",
    "8, 15, 7, 45 <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visually explore the results, I plotted a scatter plot for each model (10 per classifier) where x_axis is the p_max (how certain is the model), and y_axis is the second biggest probability. Here is an example of one of the Multi-layer Perceptron (MLP2) classifiers:"
   ]
  },
  {
   "attachments": {
    "MLP2_7.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLP2_7.jpg](attachment:MLP2_7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the green dots were classified correctly, and the red dots were not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "First, we will read the testing features from the csv file, standardize them, and reduce their dimensionality using the features_selection_model we trained on the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = pd.read_csv(songs_features_test_fname, index_col=0, header=[0, 1, 2])\n",
    "songs_names = get_songs_names(features_test)\n",
    "X = standardize_features(features_test)\n",
    "\n",
    "# Features selection\n",
    "features_selection_model = utils.load(op.join(PROJECT_FOL, 'features_selection_model.pkl'))\n",
    "X = features_selection_model.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will go over all the classifiers that we trained and saved, and use them to calculate the probabilities for all the songs' buffers in the test dataset. For each classifier, we will calculate the following scores:\n",
    "* probs_var: measures the uncertainty - low variance means high uncertainty (all the labels get similar probabilities), where high variance means low uncertainty (one high probability and all the rest are small)\n",
    "* probs_max: measures the certainty - how much the classifier is \"sure\" about its decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = glob.glob(op.join(models_fol, '*.pkl'))\n",
    "for model_fname in tqdm(models):\n",
    "    clf_name = op.basename(model_fname).split('_')[0]\n",
    "    clf = utils.load(model_fname)\n",
    "    probs = clf.predict_proba(X)\n",
    "    probs_var = np.var(probs, axis=1)\n",
    "    if np.all(probs_var == probs_var[0]):\n",
    "        continue\n",
    "    probs_max = np.max(probs, axis=1)\n",
    "    models_probs_var[clf_name].append(probs_var)\n",
    "    models_probs_max[clf_name].append(probs_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each classifier, we can average the scores for each classifier. Remember that we trained 10 times using random picking with each classifier. For each classifier, we will present the scores using a scatter plot, where the x axis is the certainty score (max_p), and the y is the uncertainty (var_p):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, model_probs_var in models_probs_var.items():\n",
    "    score, max_probs_score, var_prob_score, roc_auc_ovo, roc_auc_ovr = calc_mean_scores(all_scores, clf_name)\n",
    "    # Take only the best classifiers, who gives score * max_probs_score > 0.8\n",
    "    if score * max_probs_score < 0.8:\n",
    "        continue\n",
    "\n",
    "    # Average the scores \n",
    "    model_mean_probs_var = np.array(model_probs_var).mean(0)\n",
    "    model_mean_probs_max = np.array(models_probs_max[clf_name]).mean(0)\n",
    "    \n",
    "    songs_probs_max, songs_probs_var = defaultdict(list), defaultdict(list)\n",
    "    for ind in range(len(songs_names)):\n",
    "        songs_probs_max[songs_names[ind]].append(model_mean_probs_max[ind])\n",
    "        songs_probs_var[songs_names[ind]].append(model_mean_probs_var[ind])\n",
    "\n",
    "    # Averaging the scores for each song (each song can many scores as the number of buffers)\n",
    "    songs_probs_max_mean = [np.mean(probs) for song_name, probs in songs_probs_max.items()]\n",
    "    songs_probs_var_mean = [np.mean(probs) for song_name, probs in songs_probs_var.items()]\n",
    "\n",
    "    # Plot certainty scatter plot (max(p) / var(p)\n",
    "    plot_certainty_scatter_plot(clf_name, model_mean_probs_max, model_mean_probs_var, figures_fol)\n",
    "\n",
    "    # Sort the songs according to the certainty (songs_probs_max), from low to high\n",
    "    # Take a cutoff of 0.85, based on the MLP2 certainty scatter plot\n",
    "    # This number should be calculated automatically\n",
    "    songs_scores = sorted([(np.mean(probs), song_name) for song_name, probs in songs_probs_max.items()\n",
    "                      if (np.mean(probs) < 0.85)])\n",
    "    print('Classifier: {}'.format(clf_name))\n",
    "    print(songs_scores)\n",
    "\n",
    "\n",
    "def plot_certainty_scatter_plot(clf_name, model_mean_probs_max, model_mean_probs_var, figures_fol):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.scatter(model_mean_probs_max, model_mean_probs_var)\n",
    "    plt.title(clf_name)\n",
    "    plt.xlabel('max(p)')\n",
    "    plt.ylabel('var(p)')\n",
    "    plt.savefig(op.join(figures_fol, '{}.jpg'.format(clf_name)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the certainty (max(p) / var(p)) scatter plot using the best classifier - Multi-layer Perceptron (MLP2)"
   ]
  },
  {
   "attachments": {
    "MLP2.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLP2.jpg](attachment:MLP2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the outliers\n",
    "To choose the outliers songs - songs that weren't composed by any of the composers from the training dataset, we will find the songs with the average lowest certainty (max(p) < 0.85)\n",
    "Here are the 6 songs with the lowest certainty:\n",
    "\n",
    "* '0.3559970176888735_adj' (0.756)\n",
    "* '0.1755252422917658_adj' (0.818) \n",
    "* '0.22047111832936942_adj' (0.838)\n",
    "* '0.7491289879531658_adj' (0.84) \n",
    "* '0.337517805339117_adj' (0.84) \n",
    "* '0.23120017256495873_adj' (0.84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements \n",
    "* It's a bit hard to find the exact number of outliers. Also, a different classifier with a bit lower score would give us different results. Therefore, this approach is not very robust. Maybe an ensemble approach would help.\n",
    "* The two Multi-layer Perceptrons gave the best results, where the hidden_layer_sizes was chosen hard coded. This parameters should be tuned using hyperparameter optimization, like with the rbf and poly SVM models.\n",
    "* The number of features in the features selection process should be tuned.\n",
    "* Add more features. For example, use the Spotify APIs.\n",
    "* Neural network such as Triplet Networks might improve the solution, like in this paper:\n",
    "https://arxiv.org/abs/2008.04938\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
